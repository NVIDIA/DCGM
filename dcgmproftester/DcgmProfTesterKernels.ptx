//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-29069683
// Cuda compilation tools, release 11.1, V11.1.74
// Based on LLVM 3.4svn
//

.version 7.1
.target sm_70
.address_size 64

	// .globl	waitCycles

.visible .entry waitCycles(
	.param .u64 waitCycles_param_0,
	.param .u32 waitCycles_param_1
)
{
	.reg .pred 	%p<4>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<10>;


	ld.param.u64 	%rd4, [waitCycles_param_0];
	// inline asm
	mov.u64 	%rd5, %clock64;
	// inline asm
	ld.param.u32 	%rd2, [waitCycles_param_1];
	setp.eq.s64	%p1, %rd4, 0;
	@%p1 bra 	BB0_2;

	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mad.lo.s32 	%r4, %r2, %r3, %r1;
	cvta.to.global.u64 	%rd6, %rd4;
	mul.wide.u32 	%rd7, %r4, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.u64 	[%rd8], %rd2;

BB0_2:
	mov.u32 	%r5, %tid.x;
	add.s64 	%rd3, %rd5, %rd2;
	setp.ne.s32	%p2, %r5, 0;
	@%p2 bra 	BB0_4;

BB0_3:
	// inline asm
	mov.u64 	%rd9, %clock64;
	// inline asm
	setp.lt.u64	%p3, %rd9, %rd3;
	@%p3 bra 	BB0_3;

BB0_4:
	bar.sync 	0;
	ret;
}

	// .globl	waitNs
.visible .entry waitNs(
	.param .u64 waitNs_param_0,
	.param .u32 waitNs_param_1
)
{
	.reg .pred 	%p<4>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<10>;


	ld.param.u64 	%rd4, [waitNs_param_0];
	// inline asm
	mov.u64 %rd5, %globaltimer;
	// inline asm
	ld.param.u32 	%rd2, [waitNs_param_1];
	setp.eq.s64	%p1, %rd4, 0;
	@%p1 bra 	BB1_2;

	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mad.lo.s32 	%r4, %r2, %r3, %r1;
	cvta.to.global.u64 	%rd6, %rd4;
	mul.wide.u32 	%rd7, %r4, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.u64 	[%rd8], %rd2;

BB1_2:
	mov.u32 	%r5, %tid.x;
	add.s64 	%rd3, %rd5, %rd2;
	setp.ne.s32	%p2, %r5, 0;
	@%p2 bra 	BB1_4;

BB1_3:
	// inline asm
	mov.u64 %rd9, %globaltimer;
	// inline asm
	setp.lt.u64	%p3, %rd9, %rd3;
	@%p3 bra 	BB1_3;

BB1_4:
	bar.sync 	0;
	ret;
}

	// .globl	doWorkloadFP64
.visible .entry doWorkloadFP64(
	.param .u64 doWorkloadFP64_param_0,
	.param .u64 doWorkloadFP64_param_1
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<10>;
	.reg .f64 	%fd<10>;
	.reg .b64 	%rd<8>;


	ld.param.u64 	%rd2, [doWorkloadFP64_param_0];
	ld.param.u64 	%rd5, [doWorkloadFP64_param_1];
	// inline asm
	mov.u64 %rd3, %globaltimer;
	// inline asm
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %ntid.x;
	mov.u32 	%r6, %tid.x;
	mad.lo.s32 	%r7, %r4, %r5, %r6;
	cvt.rn.f64.u32	%fd9, %r7;
	add.s64 	%rd1, %rd3, %rd5;
	// inline asm
	mov.u64 %rd4, %globaltimer;
	// inline asm
	mov.u32 	%r3, 0;
	setp.le.u64	%p1, %rd1, %rd4;
	@%p1 bra 	BB2_4;

	mov.u32 	%r9, %r3;

BB2_2:
	add.f64 	%fd5, %fd9, 0d3FF0000000000000;
	add.f64 	%fd6, %fd5, 0d3FF0000000000000;
	add.f64 	%fd7, %fd6, 0d3FF0000000000000;
	add.f64 	%fd9, %fd7, 0d3FF0000000000000;
	add.s32 	%r9, %r9, 1;
	setp.lt.s32	%p2, %r9, 1000;
	@%p2 bra 	BB2_2;

	// inline asm
	mov.u64 %rd6, %globaltimer;
	// inline asm
	setp.gt.u64	%p3, %rd1, %rd6;
	mov.u32 	%r9, %r3;
	@%p3 bra 	BB2_2;

BB2_4:
	setp.eq.s64	%p4, %rd2, 0;
	@%p4 bra 	BB2_6;

	cvta.to.global.u64 	%rd7, %rd2;
	st.global.f64 	[%rd7], %fd9;

BB2_6:
	ret;
}

	// .globl	doWorkloadFP32
.visible .entry doWorkloadFP32(
	.param .u64 doWorkloadFP32_param_0,
	.param .u64 doWorkloadFP32_param_1
)
{
	.reg .pred 	%p<5>;
	.reg .f32 	%f<10>;
	.reg .b32 	%r<10>;
	.reg .b64 	%rd<8>;


	ld.param.u64 	%rd2, [doWorkloadFP32_param_0];
	ld.param.u64 	%rd5, [doWorkloadFP32_param_1];
	// inline asm
	mov.u64 %rd3, %globaltimer;
	// inline asm
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %ntid.x;
	mov.u32 	%r6, %tid.x;
	mad.lo.s32 	%r7, %r4, %r5, %r6;
	cvt.rn.f32.u32	%f9, %r7;
	add.s64 	%rd1, %rd3, %rd5;
	// inline asm
	mov.u64 %rd4, %globaltimer;
	// inline asm
	mov.u32 	%r3, 0;
	setp.le.u64	%p1, %rd1, %rd4;
	@%p1 bra 	BB3_4;

	mov.u32 	%r9, %r3;

BB3_2:
	add.f32 	%f5, %f9, 0f3F800000;
	add.f32 	%f6, %f5, 0f3F800000;
	add.f32 	%f7, %f6, 0f3F800000;
	add.f32 	%f9, %f7, 0f3F800000;
	add.s32 	%r9, %r9, 1;
	setp.lt.s32	%p2, %r9, 1000;
	@%p2 bra 	BB3_2;

	// inline asm
	mov.u64 %rd6, %globaltimer;
	// inline asm
	setp.gt.u64	%p3, %rd1, %rd6;
	mov.u32 	%r9, %r3;
	@%p3 bra 	BB3_2;

BB3_4:
	setp.eq.s64	%p4, %rd2, 0;
	@%p4 bra 	BB3_6;

	cvta.to.global.u64 	%rd7, %rd2;
	st.global.f32 	[%rd7], %f9;

BB3_6:
	ret;
}

	// .globl	doWorkloadFP16
.visible .entry doWorkloadFP16(
	.param .u64 doWorkloadFP16_param_0,
	.param .u64 doWorkloadFP16_param_1
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<22>;
	.reg .b32 	%r<10>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<8>;


	ld.param.u64 	%rd2, [doWorkloadFP16_param_0];
	ld.param.u64 	%rd5, [doWorkloadFP16_param_1];
	// inline asm
	mov.u64 %rd3, %globaltimer;
	// inline asm
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %ntid.x;
	mov.u32 	%r6, %tid.x;
	mad.lo.s32 	%r7, %r4, %r5, %r6;
	cvt.rn.f64.u32	%fd1, %r7;
	// inline asm
	{  cvt.rn.f16.f64 %rs21, %fd1;}

	// inline asm
	mov.f64 	%fd2, 0d3FF0000000000000;
	// inline asm
	{  cvt.rn.f16.f64 %rs7, %fd2;}

	// inline asm
	add.s64 	%rd1, %rd3, %rd5;
	// inline asm
	mov.u64 %rd4, %globaltimer;
	// inline asm
	mov.u32 	%r3, 0;
	setp.le.u64	%p1, %rd1, %rd4;
	@%p1 bra 	BB4_4;

	mov.u32 	%r9, %r3;

BB4_2:
	// inline asm
	{add.f16 %rs8,%rs21,%rs7;
}
	// inline asm
	// inline asm
	{add.f16 %rs11,%rs8,%rs7;
}
	// inline asm
	// inline asm
	{add.f16 %rs14,%rs11,%rs7;
}
	// inline asm
	// inline asm
	{add.f16 %rs21,%rs14,%rs7;
}
	// inline asm
	add.s32 	%r9, %r9, 1;
	setp.lt.s32	%p2, %r9, 1000;
	@%p2 bra 	BB4_2;

	// inline asm
	mov.u64 %rd6, %globaltimer;
	// inline asm
	setp.gt.u64	%p3, %rd1, %rd6;
	mov.u32 	%r9, %r3;
	@%p3 bra 	BB4_2;

BB4_4:
	setp.eq.s64	%p4, %rd2, 0;
	@%p4 bra 	BB4_6;

	cvta.to.global.u64 	%rd7, %rd2;
	st.global.u16 	[%rd7], %rs21;

BB4_6:
	ret;
}


